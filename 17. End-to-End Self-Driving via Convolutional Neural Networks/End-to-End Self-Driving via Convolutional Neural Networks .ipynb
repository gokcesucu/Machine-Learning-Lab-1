{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**IMPORTING THE NECESSARY LIBRARIES**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2022-01-14T22:43:47.982795Z",
     "iopub.status.busy": "2022-01-14T22:43:47.982467Z",
     "iopub.status.idle": "2022-01-14T22:43:50.086555Z",
     "shell.execute_reply": "2022-01-14T22:43:50.085089Z",
     "shell.execute_reply.started": "2022-01-14T22:43:47.982763Z"
    }
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, Dataset\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import os\n",
    "import cv2\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**CREATING THE DATASET**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-14T22:43:50.788605Z",
     "iopub.status.busy": "2022-01-14T22:43:50.788327Z",
     "iopub.status.idle": "2022-01-14T22:43:50.796977Z",
     "shell.execute_reply": "2022-01-14T22:43:50.795902Z",
     "shell.execute_reply.started": "2022-01-14T22:43:50.788561Z"
    }
   },
   "outputs": [],
   "source": [
    "class Dataset(Dataset):\n",
    "    def __init__(self):\n",
    "        self.filepath ='/kaggle/input/car-steering-angle-prediction/driving_dataset/'\n",
    "        self.filenames = os.listdir(self.filepath)\n",
    "    \n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.filenames)\n",
    "    \n",
    "    def __getitem__(self,index):\n",
    "        filename = self.filenames[index]\n",
    "        img = cv2.imread(self.filepath+filename)\n",
    "        \n",
    "        resized = cv2.resize(img, (66,200),interpolation=cv2.INTER_AREA)\n",
    "        return torch.from_numpy(resized.transpose()).float(), torch.rand(1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**LOADING DATA**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-14T22:43:51.710841Z",
     "iopub.status.busy": "2022-01-14T22:43:51.709379Z",
     "iopub.status.idle": "2022-01-14T22:43:52.348652Z",
     "shell.execute_reply": "2022-01-14T22:43:52.348089Z",
     "shell.execute_reply.started": "2022-01-14T22:43:51.710770Z"
    }
   },
   "outputs": [],
   "source": [
    "data = Dataset()\n",
    "data_loader = torch.utils.data.DataLoader(data,batch_size=32 ,shuffle=True )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the data ,there are tuples whch its first elemnt is tensor and second element is angle. We will try to predict the angle by using tensors which represents the pictures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-14T22:43:52.665045Z",
     "iopub.status.busy": "2022-01-14T22:43:52.664708Z",
     "iopub.status.idle": "2022-01-14T22:43:52.752782Z",
     "shell.execute_reply": "2022-01-14T22:43:52.751303Z",
     "shell.execute_reply.started": "2022-01-14T22:43:52.665014Z"
    }
   },
   "outputs": [],
   "source": [
    "print('Dimension of Images',data[0][0].shape)\n",
    "print('numberofsample',len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-14T22:43:53.941331Z",
     "iopub.status.busy": "2022-01-14T22:43:53.940849Z",
     "iopub.status.idle": "2022-01-14T22:43:54.049206Z",
     "shell.execute_reply": "2022-01-14T22:43:54.048235Z",
     "shell.execute_reply.started": "2022-01-14T22:43:53.941301Z"
    }
   },
   "outputs": [],
   "source": [
    "print('Numerical Representations of Images',data[0][0],'\\n')\n",
    "print('Angle of Car Steel on The image', data[0][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**SPLITTING INTO TEST TRAIN AND VALIDATION**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-14T22:43:55.893487Z",
     "iopub.status.busy": "2022-01-14T22:43:55.893086Z",
     "iopub.status.idle": "2022-01-14T22:43:55.899746Z",
     "shell.execute_reply": "2022-01-14T22:43:55.898855Z",
     "shell.execute_reply.started": "2022-01-14T22:43:55.893458Z"
    }
   },
   "outputs": [],
   "source": [
    "train =list(range(0,30000))\n",
    "test = list(range(30000,40000))\n",
    "valid =list(range(40000,45570))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-14T22:44:22.708322Z",
     "iopub.status.busy": "2022-01-14T22:44:22.708038Z",
     "iopub.status.idle": "2022-01-14T22:44:22.716347Z",
     "shell.execute_reply": "2022-01-14T22:44:22.715292Z",
     "shell.execute_reply.started": "2022-01-14T22:44:22.708292Z"
    }
   },
   "outputs": [],
   "source": [
    "trainset = torch.utils.data.Subset(data, train)\n",
    "testset = torch.utils.data.Subset(data, test)\n",
    "validset=torch.utils.data.Subset(data, valid)\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=32,shuffle=True)\n",
    "testloader= torch.utils.data.DataLoader(testset, batch_size=32,shuffle=True)\n",
    "validloader= torch.utils.data.DataLoader(validset, batch_size=32,shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-14T22:44:23.839382Z",
     "iopub.status.busy": "2022-01-14T22:44:23.838977Z",
     "iopub.status.idle": "2022-01-14T22:44:23.846415Z",
     "shell.execute_reply": "2022-01-14T22:44:23.845412Z",
     "shell.execute_reply.started": "2022-01-14T22:44:23.839353Z"
    }
   },
   "outputs": [],
   "source": [
    "print('Train Set Samples:',len(trainset))\n",
    "print('Test Set Samples',len(testset))\n",
    "print('Valid Set Samples',len(validset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-14T22:44:24.182814Z",
     "iopub.status.busy": "2022-01-14T22:44:24.182250Z",
     "iopub.status.idle": "2022-01-14T22:44:24.195957Z",
     "shell.execute_reply": "2022-01-14T22:44:24.195308Z",
     "shell.execute_reply.started": "2022-01-14T22:44:24.182784Z"
    }
   },
   "outputs": [],
   "source": [
    "trainset[0][0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**CONVOLUTIONAL MODEL**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-14T22:44:25.015918Z",
     "iopub.status.busy": "2022-01-14T22:44:25.014606Z",
     "iopub.status.idle": "2022-01-14T22:44:25.027059Z",
     "shell.execute_reply": "2022-01-14T22:44:25.025493Z",
     "shell.execute_reply.started": "2022-01-14T22:44:25.015852Z"
    }
   },
   "outputs": [],
   "source": [
    "class paper_model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(paper_model, self).__init__()\n",
    "\n",
    "        self.conv_layers = nn.Sequential(\n",
    "            \n",
    "            #conv2d pytrochs implementation of convolutional layers\n",
    "            nn.Conv2d(3, 24, kernel_size=5, stride=2),\n",
    "            nn.ELU(),\n",
    "            \n",
    "            nn.Conv2d(24, 36, kernel_size=5, stride=2),\n",
    "            nn.ELU(),\n",
    "            \n",
    "            nn.Conv2d(36, 48, kernel_size=5, stride=2),\n",
    "            nn.ELU(),\n",
    "            \n",
    "            nn.Conv2d(48, 64, kernel_size=3, stride=1),\n",
    "            nn.ELU(),\n",
    "            \n",
    "            nn.Conv2d(64, 64, kernel_size=3, stride=1),\n",
    "            nn.ELU(),\n",
    "            \n",
    "            nn.Dropout(p=0.5)\n",
    "        )\n",
    "        \n",
    "        self.linear_layers = nn.Sequential(\n",
    "            \n",
    "            #linear fully connected layers\n",
    "            nn.Linear(in_features=64*1*18, out_features=100),\n",
    "            nn.ELU(),\n",
    "            nn.Dropout(p=0.4),\n",
    "            \n",
    "            nn.Linear(in_features=100, out_features=64),\n",
    "            nn.ELU(),\n",
    "            \n",
    "            nn.Linear(in_features=64, out_features=10),\n",
    "            nn.ELU(),\n",
    "            \n",
    "            nn.Linear(in_features=10, out_features=1)\n",
    "        )\n",
    "        \n",
    "    \n",
    "    def forward(self, x):\n",
    "        #input image size:\n",
    "        x = x.view(x.size(0), 3, 66, 200)\n",
    "        output = self.conv_layers(x)\n",
    "        output = output.view(output.size(0), -1)\n",
    "        output = self.linear_layers(output)\n",
    "        return output\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**SETTING OPTIMIZATION**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-14T22:44:25.726532Z",
     "iopub.status.busy": "2022-01-14T22:44:25.726054Z",
     "iopub.status.idle": "2022-01-14T22:44:25.740900Z",
     "shell.execute_reply": "2022-01-14T22:44:25.740333Z",
     "shell.execute_reply.started": "2022-01-14T22:44:25.726500Z"
    }
   },
   "outputs": [],
   "source": [
    "net = paper_model()\n",
    "optimizer = torch.optim.Adam(net.parameters(),lr =1e-3)\n",
    "criterion = torch.nn.MSELoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TRAINING**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-14T22:44:26.289272Z",
     "iopub.status.busy": "2022-01-14T22:44:26.288961Z",
     "iopub.status.idle": "2022-01-14T22:50:50.111833Z",
     "shell.execute_reply": "2022-01-14T22:50:50.108344Z",
     "shell.execute_reply.started": "2022-01-14T22:44:26.289241Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "image_loss = []\n",
    "for i, sample in enumerate(trainloader):\n",
    "    optimizer.zero_grad()\n",
    "    prediction = net(sample[0])\n",
    "    loss = criterion(prediction.squeeze() , torch.rand(1))\n",
    "    print(f\"{i}th loss: \", loss.item())\n",
    "    image_loss.append(loss)\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**RMSE**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-14T22:58:06.469568Z",
     "iopub.status.busy": "2022-01-14T22:58:06.469301Z",
     "iopub.status.idle": "2022-01-14T22:58:06.482652Z",
     "shell.execute_reply": "2022-01-14T22:58:06.481478Z",
     "shell.execute_reply.started": "2022-01-14T22:58:06.469538Z"
    }
   },
   "outputs": [],
   "source": [
    "rmse = []\n",
    "for i in image_loss:\n",
    "    rmse.append(i**0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-14T22:58:31.438050Z",
     "iopub.status.busy": "2022-01-14T22:58:31.437743Z",
     "iopub.status.idle": "2022-01-14T22:58:31.611250Z",
     "shell.execute_reply": "2022-01-14T22:58:31.610143Z",
     "shell.execute_reply.started": "2022-01-14T22:58:31.438021Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.title('LOSS FOR EACH IMAGE')\n",
    "plt.xlabel('Image Number')\n",
    "plt.ylabel('RMSE')\n",
    "plt.plot(rmse)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TOTAL RMSE**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-14T23:00:29.430668Z",
     "iopub.status.busy": "2022-01-14T23:00:29.430274Z",
     "iopub.status.idle": "2022-01-14T23:00:29.441639Z",
     "shell.execute_reply": "2022-01-14T23:00:29.440518Z",
     "shell.execute_reply.started": "2022-01-14T23:00:29.430639Z"
    }
   },
   "outputs": [],
   "source": [
    "print('Total RMSE:', sum(rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
